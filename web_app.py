import streamlit as st
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
import tempfile
import os

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="YOLOv12 ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ”",
    layout="wide"
)

# æ•°æ®é›†ç±»åˆ«æ˜ å°„
CLASS_MAP = {
    "Prionailurus bengalensis": "è±¹çŒ«",
    "Vulpes vulpes": "èµ¤ç‹",
    "Muntiacus vaginalis": "èµ¤éº‚",
    "Paguma larvata": "æœå­ç‹¸",
    "Ursus thibetanus": "é»‘ç†Š",
    "Cervus nippon": "æ¢…èŠ±é¹¿",
    "Macaca mulatta": "çŒ•çŒ´",
    "Lepus sinensis": "é‡å…”",
    "Sus scrofa": "é‡çŒª",
    "Naemorhedus griseus": "ä¸­åæ–‘ç¾š"
}

# åº”ç”¨æ ‡é¢˜
st.title("ğŸ¯ YOLOv12 ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")

# åˆå§‹åŒ–æ¨¡å‹
@st.cache_resource
def load_model():
    return YOLO("best.pt")

model = load_model()

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    conf_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.25, 0.05)
    iou_threshold = st.slider("IoUé˜ˆå€¼", 0.0, 1.0, 0.45, 0.05)
    
    st.header("ğŸš€ åŠŸèƒ½")
    detection_mode = st.radio("æ£€æµ‹æ¨¡å¼", ["å›¾ç‰‡æ£€æµ‹", "è§†é¢‘æ£€æµ‹"])

# ä¸»ç•Œé¢
col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ–¼ï¸ åŸå§‹å›¾åƒ")
    raw_placeholder = st.empty()

with col2:
    st.subheader("ğŸ” æ£€æµ‹ç»“æœ")  
    result_placeholder = st.empty()

# æ£€æµ‹ç»“æœ
st.subheader("ğŸ“Š æ£€æµ‹ç»“æœ")
table_placeholder = st.empty()

# å›¾ç‰‡æ£€æµ‹
if detection_mode == "å›¾ç‰‡æ£€æµ‹":
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])
    
    if uploaded_file is not None:
        try:
            image = Image.open(uploaded_file)
            image_np = np.array(image)
            raw_placeholder.image(image, use_column_width=True)
            
            with st.spinner("æ£€æµ‹ä¸­..."):
                results = model.predict(image_np, conf=conf_threshold, iou=iou_threshold)
                result_image = results[0].plot()
                result_image_rgb = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)
                result_placeholder.image(result_image_rgb, use_column_width=True)
                
                if len(results[0].boxes) > 0:
                    detections = []
                    for det in results[0].boxes:
                        latin_name = results[0].names[int(det.cls)]
                        chinese_name = CLASS_MAP.get(latin_name, latin_name)
                        conf_val = float(det.conf)
                        x = float(det.xyxy[0][0])
                        y = float(det.xyxy[0][1])
                        
                        detections.append({
                            "ç±»åˆ«": chinese_name,
                            "ç½®ä¿¡åº¦": f"{conf_val:.2f}",
                            "ä½ç½®(x)": f"{x:.2f}",
                            "ä½ç½®(y)": f"{y:.2f}"
                        })
                    
                    table_placeholder.dataframe(detections)
                else:
                    table_placeholder.warning("æœªæ£€æµ‹åˆ°ç›®æ ‡")
                    
        except Exception as e:
            st.error(f"é”™è¯¯: {str(e)}")

# è§†é¢‘æ£€æµ‹
elif detection_mode == "è§†é¢‘æ£€æµ‹":
    st.info("è§†é¢‘æ£€æµ‹åŠŸèƒ½éœ€è¦è¾ƒé•¿æ—¶é—´å¤„ç†")
    uploaded_video = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=['mp4', 'avi', 'mov'])
    
    if uploaded_video and st.button("å¼€å§‹æ£€æµ‹"):
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_video.read())
            video_path = tmp_file.name
        
        try:
            cap = cv2.VideoCapture(video_path)
            frame_placeholder = st.empty()
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                results = model.predict(frame, conf=conf_threshold, iou=iou_threshold)
                result_frame = results[0].plot()
                result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
                frame_placeholder.image(result_frame_rgb)
            
            cap.release()
            st.success("æ£€æµ‹å®Œæˆ!")
            
        except Exception as e:
            st.error(f"é”™è¯¯: {str(e)}")
        finally:
            if os.path.exists(video_path):
                os.unlink(video_path)

st.markdown("---")
st.markdown("YOLOv12 ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")
